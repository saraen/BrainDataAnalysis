{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">TFM - Data Mining and Machine Learning </p>\n",
    "<p style=\"margin: 0; text-align:right;\">2019 · Master in Data science</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Sara Estravís Nieto</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# SC Brain Matrix Classification\n",
    "\n",
    "<ul>\n",
    "  <li><a href='#dataload'>Data load</a></li>\n",
    "  <li><a href='#knn'>K-NN</a></li>\n",
    "  <li><a href='#svm'>SVM</a></li>\n",
    "  <li><a href='#randomforest'>Random Forest</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'dataload'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the csv brain data with the significant variables\n",
    "data = pd.read_csv(\"SCMatrixSignificantData.csv\") \n",
    "\n",
    "# Shuffle the data\n",
    "data = shuffle(data, random_state=0).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataframe into nodes_properties (x) and classes (y)\n",
    "nodes_properties = data.iloc[:,0:len(data.columns)-1]\n",
    "print('Properties dimensions: ', nodes_properties.shape)\n",
    "\n",
    "classes = data.iloc[:,len(data.columns)-1]\n",
    "classes_names = [\"hv\", \"ms\"]\n",
    "n_classes = len(classes_names)\n",
    "print('Classes dimensions: ', classes.shape)\n",
    "print('There are {} classes: {}'.format(n_classes, classes_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataframe in the test and train sets, with 80% of the data in the train group and 20% in the test set.\n",
    "# We will stratify using classes, so that there is the same proportion of each class in the test/train sets as in the original\n",
    "# dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(nodes_properties, classes, test_size=0.2, random_state=2019, stratify=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train dimensions: ', X_train.shape)\n",
    "print('y_train dimensions: ', y_train.shape)\n",
    "\n",
    "print('X_test dimensions: ', X_test.shape)\n",
    "print('y_test dimensions: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, create the classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Then, the hyperparameters to be optimized are defined \n",
    "# k = number of nearest neighbours considered\n",
    "# weights = weight function used in prediction. If it is 'uniform', all the neighbours will have the same importance. If it is \n",
    "# 'distance', closer neighbours will have more influence. \n",
    "\n",
    "k_range = list(range(1, 21))\n",
    "weight_names = ['uniform', 'distance']\n",
    "\n",
    "param_grid = dict(n_neighbors=k_range, weights = weight_names)\n",
    "\n",
    "# Now create the grid search with 4 folds for cross-validation\n",
    "grid = GridSearchCV(knn, param_grid, cv=4, iid=False)\n",
    "\n",
    "# Apply the grid to the data checking the time \n",
    "start = time()\n",
    "grid.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "# Check the results\n",
    "print(\"The search took {} seconds\".format(end - start))\n",
    "print(\" \")\n",
    "\n",
    "ranks = list(grid.cv_results_['rank_test_score'])\n",
    "means = list(grid.cv_results_[\"mean_test_score\"])\n",
    "stds = list(grid.cv_results_[\"std_test_score\"])\n",
    "params = list(grid.cv_results_['params'])\n",
    "\n",
    "results = zip (ranks, means, stds, params)\n",
    "for rank, mean, std, params in results:\n",
    "    if rank == 1: #If the rank of the result is one, print it\n",
    "        print(\"Rank : {}. Mean accuracy {:.4f} +/- {:.4f}. Parameters: {}\".format(rank, mean*100, std*100, params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create and fit the model with the best hyperparameters\n",
    "knn = KNeighborsClassifier(n_neighbors=grid.best_params_[\"n_neighbors\"], weights=grid.best_params_[\"weights\"])\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test values\n",
    "y_predicted = knn.predict(X_test)\n",
    "\n",
    "# Get the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "# Print the results\n",
    "print(\"K-NN Algorithm results\")\n",
    "print(\"-----------------------\")\n",
    "print(\"Optimal k: {}\".format(grid.best_params_[\"n_neighbors\"]))\n",
    "print(\"Optimal weights: {}\".format(grid.best_params_[\"weights\"]))\n",
    "print(\"Accuracy in the test set with the optimal parameters: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix plot function\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_matrix, classes=classes_names,\n",
    "                      title='Matriz de confusión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "svm_clasif = SVC(random_state = 1)\n",
    "\n",
    "# Define the hyperparameters to be optimized\n",
    "param_dist = dict(C=uniform(1, 100), gamma=uniform(0.001, 1))\n",
    "\n",
    "# Now create the randomnized search with 4 folds for cross-validation\n",
    "num_iterations = 100\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "rand = RandomizedSearchCV(svm_clasif, param_distributions = param_dist, cv=cv, n_iter=num_iterations)\n",
    "\n",
    "# Apply the search to the data checking the time \n",
    "start = time()\n",
    "rand.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "# Check the results\n",
    "print(\"The search took {} seconds\".format(end - start))\n",
    "print(\" \")\n",
    "\n",
    "ranks = list(rand.cv_results_['rank_test_score'])\n",
    "means = list(rand.cv_results_[\"mean_test_score\"])\n",
    "stds = list(rand.cv_results_[\"std_test_score\"])\n",
    "params = list(rand.cv_results_['params'])\n",
    "\n",
    "results = zip (ranks, means, stds, params)\n",
    "for rank, mean, std, params in results:\n",
    "    if rank == 1: #If the rank of the result is one, print it\n",
    "        print(\"Rank : {}. Mean accuracy {:.4f} +/- {:.4f}. Parameters: {}\".format(rank, mean*100, std*100, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model with the best hyperparameters\n",
    "svm_clasif = SVC(C=rand.best_params_[\"C\"], gamma=rand.best_params_[\"gamma\"])\n",
    "svm_clasif.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test values\n",
    "y_predicted = svm_clasif.predict(X_test)\n",
    "\n",
    "# Get the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "# Print the results\n",
    "print(\"SVM Algorithm results\")\n",
    "print(\"-----------------------\")\n",
    "print(\"Optimal C: {}\".format(rand.best_params_[\"C\"]))\n",
    "print(\"Optimal gamma: {}\".format(rand.best_params_[\"gamma\"]))\n",
    "print(\"Accuracy in the test set with the optimal parameters: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_matrix, classes=classes_names,\n",
    "                      title='Matriz de confusión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='randomforest'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "random_forest = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define the hyperparameters to be optimized \n",
    "n_estimators = list(range(1, 61))\n",
    "max_depth = range(1, 100, 10)\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth = max_depth)\n",
    "\n",
    "# Create the grid search with 4 folds for cross-validation\n",
    "grid = GridSearchCV(random_forest, param_grid, cv=4, iid=False)\n",
    "\n",
    "# Apply the grid to the data checking the time \n",
    "start = time()\n",
    "grid.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "# Check the results\n",
    "print(\"The search took {} seconds\".format(end - start))\n",
    "print(\" \")\n",
    "\n",
    "ranks = list(grid.cv_results_['rank_test_score'])\n",
    "means = list(grid.cv_results_[\"mean_test_score\"])\n",
    "stds = list(grid.cv_results_[\"std_test_score\"])\n",
    "params = list(grid.cv_results_['params'])\n",
    "\n",
    "results = zip (ranks, means, stds, params)\n",
    "for rank, mean, std, params in results:\n",
    "    if rank == 1: #If the rank of the result is one, print it\n",
    "        print(\"Rank : {}. Mean accuracy {:.4f} +/- {:.4f}. Parameters: {}\".format(rank, mean*100, std*100, params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model with the best hyperparameters\n",
    "random_forest = RandomForestClassifier(random_state=0, n_estimators=grid.best_params_[\"n_estimators\"], max_depth=grid.best_params_[\"max_depth\"])\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test values\n",
    "y_predicted = random_forest.predict(X_test)\n",
    "\n",
    "# Get the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "# Print the results\n",
    "print(\"Random Forest Algorithm results\")\n",
    "print(\"-----------------------\")\n",
    "print(\"Optimal n_estimators: {}\".format(grid.best_params_[\"n_estimators\"]))\n",
    "print(\"Optimal max_depth: {}\".format(grid.best_params_[\"max_depth\"]))\n",
    "print(\"Accuracy in the test set with the optimal parameters: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_matrix, classes=classes_names,\n",
    "                      title='Matriz de confusión')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
